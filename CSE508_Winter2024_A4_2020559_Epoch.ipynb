{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T01:21:55.569478Z","iopub.status.busy":"2024-04-23T01:21:55.569180Z","iopub.status.idle":"2024-04-23T01:22:05.369033Z","shell.execute_reply":"2024-04-23T01:22:05.368260Z","shell.execute_reply.started":"2024-04-23T01:21:55.569453Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T01:22:05.371854Z","iopub.status.busy":"2024-04-23T01:22:05.370876Z","iopub.status.idle":"2024-04-23T01:22:17.920535Z","shell.execute_reply":"2024-04-23T01:22:17.919187Z","shell.execute_reply.started":"2024-04-23T01:22:05.371814Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('Reviews.csv')\n","\n","data = data[['Text', 'Summary']].dropna()\n","\n","data['Text'] = data['Text'].str.lower()\n","data['Summary'] = data['Summary'].str.lower()\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2LMHeadModel.from_pretrained('gpt2')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T01:22:17.922859Z","iopub.status.busy":"2024-04-23T01:22:17.922435Z","iopub.status.idle":"2024-04-23T01:22:18.128641Z","shell.execute_reply":"2024-04-23T01:22:18.127667Z","shell.execute_reply.started":"2024-04-23T01:22:17.922822Z"},"trusted":true},"outputs":[],"source":["# Divide the dataset into training and testing (75:25)\n","data_used, waste_data = train_test_split(data, test_size=0.6, random_state=42)\n","train_data, test_data = train_test_split(data_used, test_size=0.25, random_state=42)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T01:22:18.130733Z","iopub.status.busy":"2024-04-23T01:22:18.130446Z","iopub.status.idle":"2024-04-23T01:22:18.142310Z","shell.execute_reply":"2024-04-23T01:22:18.141392Z","shell.execute_reply.started":"2024-04-23T01:22:18.130710Z"},"trusted":true},"outputs":[],"source":["# Implement a custom dataset class\n","class ReviewDataset(Dataset):\n","    def __init__(self, texts, summaries, tokenizer, max_length=40):\n","        self.texts = texts\n","        self.summaries = summaries\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","    \n","    def __len__(self):\n","        return len(self.texts)\n","    \n","    def __getitem__(self, idx):\n","        text = self.texts.iloc[idx]\n","        summary = self.summaries.iloc[idx]\n","\n","        input_ids = self.tokenizer.encode(text, truncation=True, max_length=self.max_length, padding='max_length')\n","        labels = self.tokenizer.encode(summary, truncation=True, max_length=self.max_length, padding='max_length')\n","        \n","        return torch.tensor(input_ids), torch.tensor(labels)\n","\n","# Initialize datasets and dataloaders\n","train_dataset = ReviewDataset(train_data['Text'], train_data['Summary'], tokenizer)\n","test_dataset = ReviewDataset(test_data['Text'], test_data['Summary'], tokenizer)\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T01:22:18.143979Z","iopub.status.busy":"2024-04-23T01:22:18.143716Z","iopub.status.idle":"2024-04-23T01:22:18.290060Z","shell.execute_reply":"2024-04-23T01:22:18.289152Z","shell.execute_reply.started":"2024-04-23T01:22:18.143956Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T01:22:18.291462Z","iopub.status.busy":"2024-04-23T01:22:18.291126Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:   0%|          | 0/10658 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:   5%|▍         | 499/10658 [02:13<45:22,  3.73it/s]"]},{"name":"stdout","output_type":"stream","text":["500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:   9%|▉         | 999/10658 [04:28<43:21,  3.71it/s]"]},{"name":"stdout","output_type":"stream","text":["1000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  14%|█▍        | 1499/10658 [06:43<40:22,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["1500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  19%|█▉        | 1999/10658 [08:57<38:12,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["2000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  23%|██▎       | 2499/10658 [11:11<36:54,  3.68it/s]"]},{"name":"stdout","output_type":"stream","text":["2500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  28%|██▊       | 2999/10658 [13:24<34:02,  3.75it/s]"]},{"name":"stdout","output_type":"stream","text":["3000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  33%|███▎      | 3499/10658 [15:37<31:39,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["3500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  38%|███▊      | 3999/10658 [17:50<31:25,  3.53it/s]"]},{"name":"stdout","output_type":"stream","text":["4000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  42%|████▏     | 4499/10658 [20:03<27:08,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["4500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  47%|████▋     | 4999/10658 [22:16<24:54,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["5000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  52%|█████▏    | 5499/10658 [24:28<22:46,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["5500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  56%|█████▋    | 5999/10658 [26:41<20:24,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["6000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  61%|██████    | 6499/10658 [28:53<18:18,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["6500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  66%|██████▌   | 6999/10658 [31:06<15:57,  3.82it/s]"]},{"name":"stdout","output_type":"stream","text":["7000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  70%|███████   | 7499/10658 [33:18<13:51,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["7500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  75%|███████▌  | 7999/10658 [35:30<12:38,  3.51it/s]"]},{"name":"stdout","output_type":"stream","text":["8000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  80%|███████▉  | 8499/10658 [37:43<09:28,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["8500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  84%|████████▍ | 8999/10658 [39:56<07:20,  3.77it/s]"]},{"name":"stdout","output_type":"stream","text":["9000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  89%|████████▉ | 9499/10658 [42:08<05:09,  3.74it/s]"]},{"name":"stdout","output_type":"stream","text":["9500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  94%|█████████▍| 9999/10658 [44:20<02:55,  3.76it/s]"]},{"name":"stdout","output_type":"stream","text":["10000\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1:  99%|█████████▊| 10499/10658 [46:34<00:43,  3.69it/s]"]},{"name":"stdout","output_type":"stream","text":["10500\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/1: 100%|██████████| 10658/10658 [47:16<00:00,  3.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average training loss: 0.9562280519015571\n"]}],"source":["# Fine-tune the GPT-2 model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","epochs = 1\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","torch.cuda.empty_cache()\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    c=0\n","    for input_ids, labels in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{epochs}'):\n","        c+=1\n","        if c%500==0:\n","            print(c)\n","        input_ids = input_ids.to(device)\n","        labels = labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        outputs = model(input_ids=input_ids, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        torch.cuda.empty_cache()\n","    avg_train_loss = total_loss / len(train_dataloader)\n","    print(f'Average training loss: {avg_train_loss}')\n","\n","# Save the fine-tuned model\n","model.save_pretrained('fine_tuned_gpt2_model')\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["model.save_pretrained('fine_tuned_gpt2_model_epoch')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T20:27:06.568626Z","iopub.status.busy":"2024-04-22T20:27:06.567679Z","iopub.status.idle":"2024-04-22T20:27:06.604211Z","shell.execute_reply":"2024-04-22T20:27:06.603145Z","shell.execute_reply.started":"2024-04-22T20:27:06.568593Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rouge in c:\\users\\yeled\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.1)\n","Requirement already satisfied: six in c:\\users\\yeled\\appdata\\roaming\\python\\python311\\site-packages (from rouge) (1.16.0)\n"]}],"source":["!pip install rouge\n","from rouge import Rouge\n","\n","def calculate_rouge_scores(hypotheses, references):\n","    rouge = Rouge()\n","    scores = rouge.get_scores(hypotheses, references, avg=True)\n","    return scores"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:14:43.006755Z","iopub.status.idle":"2024-04-22T20:14:43.007188Z","shell.execute_reply":"2024-04-22T20:14:43.006985Z","shell.execute_reply.started":"2024-04-22T20:14:43.006966Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [04:42<00:00, 12.58it/s]\n"]}],"source":["from transformers.utils import logging\n","logging.set_verbosity_error()\n","list_of_rouge = []\n","\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","# for input_ids, labels in tqdm(test_dataloader, desc=f'Epoch {epoch + 1}/{epochs}'):\n","for input_ids, labels in tqdm(test_dataloader):\n","        \n","    input_ids = input_ids.to(device)\n","    labels = labels.to(device)\n","    attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(device)\n","    pad_token_id = tokenizer.eos_token_id\n","    \n","    outputs = model.generate(input_ids, attention_mask=attention_mask, pad_token_id=pad_token_id, max_new_tokens=10)\n","    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    labels_text = tokenizer.decode(labels[0], skip_special_tokens=True)\n","    roug_score = calculate_rouge_scores(output_text, labels_text)\n","    list_of_rouge.append(roug_score)\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'rouge-1': {'f': 0.0841702417285644, 'p': 0.051084033100745045, 'r': 0.3079353399021223}, 'rouge-2': {'f': 0.020264212268463918, 'p': 0.012273728389982757, 'r': 0.0889187865602414}, 'rouge-l': {'f': 0.07986952382854193, 'p': 0.04838538159016817, 'r': 0.2949689895110542}}\n"]}],"source":["final_rouge = {'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0},'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},'rouge-l': {'f': 0.0, 'p': 0.0, 'r': 0.0}}\n","for rg in list_of_rouge:\n","    final_rouge['rouge-1']['r']+=rg['rouge-1']['r']\n","    final_rouge['rouge-1']['p']+=rg['rouge-1']['p']\n","    final_rouge['rouge-1']['f']+=rg['rouge-1']['f']\n","    final_rouge['rouge-2']['r']+=rg['rouge-2']['r']\n","    final_rouge['rouge-2']['p']+=rg['rouge-2']['p']\n","    final_rouge['rouge-2']['f']+=rg['rouge-2']['f']\n","    final_rouge['rouge-l']['r']+=rg['rouge-l']['r']\n","    final_rouge['rouge-l']['p']+=rg['rouge-l']['p']\n","    final_rouge['rouge-l']['f']+=rg['rouge-l']['f']\n","\n","final_rouge['rouge-1']['r']/=len(list_of_rouge)\n","final_rouge['rouge-1']['p']/=len(list_of_rouge)\n","final_rouge['rouge-1']['f']/=len(list_of_rouge)\n","final_rouge['rouge-2']['r']/=len(list_of_rouge)\n","final_rouge['rouge-2']['p']/=len(list_of_rouge)\n","final_rouge['rouge-2']['f']/=len(list_of_rouge)\n","final_rouge['rouge-l']['r']/=len(list_of_rouge)\n","final_rouge['rouge-l']['p']/=len(list_of_rouge)\n","final_rouge['rouge-l']['f']/=len(list_of_rouge)\n","\n","print(final_rouge)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":18,"sourceId":2157,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
